
# Архитектура Elasticsearch

Elasticsearch — это не просто база данных, а **распределенный поисковый движок**. Его архитектура заточена под одну цель: невероятно быстро искать и анализировать данные. Вот его ключевые компоненты.

#### **1. Основные концепции и структура данных**

| Концепция | Аналог в RDBMS | Описание |
| :--- | :--- | :--- |
| **Индекс (Index)** | База данных / Таблица | Коллекция документов, объединенных общими характеристиками (например, индекс `products`, `logs`). |
| **Документ (Document)** | Строка в таблице | Базовая единица информации в JSON-формате, которую мы индексируем и ищем. |
| **Поле (Field)** | Колонка в таблице | Отдельный ключ/значение в JSON-документе (например, `"title": "Книга"`). |
| **Маппинг (Mapping)** | Схема таблицы | Определяет, как документ и его поля проиндексированы и хранятся (типы данных — text, keyword, integer; анализаторы и т.д.). **В отличие от RDBMS, схема динамическая и может определяться на лету.** |
| **Шард (Shard)** | Горизонтальное партиционирование | **Любой индекс делится на одну или несколько частей — шардов.** Это единица горизонтального масштабирования и параллелизации. |
| **Реплика (Replica)** | Резервная копия | Точная копия шарда. Обеспечивает отказоустойчивость и повышает производительность на чтение. |

**Как это выглядит на практике:**
*   Вы создаете индекс `my-logs-2023.10.27`.
*   Elasticsearch делит его, например, на **5 первичных шардов (primary shards)** и **по 1 реплике на каждый** (итого 10 шардов).
*   Эти шарды распределяются по нодам в кластере. Если одна нода падает, ее шарды будут восстановлены из реплик на других нодах.

#### **2. Кластер, ноды и их роли**

Elasticsearch работает в виде **кластера** — набора из одного или нескольких серверов.

*   **Нода (Node)** — это один запущенный экземпляр (процесс) Elasticsearch, который является частью кластера.
*   Ноды могут выполнять разные роли для эффективного распределения нагрузки:
    *   **Master-eligible node:** Управляет кластером: создает/удаляет индексы, отслеживает состояние нод, распределяет шарды. (Для отказоустойчивости таких нод должно быть не менее 3).
    *   **Data node:** Хранит данные, выполняет операции индексирования, поиска и агрегации. Это "рабочие лошадки", которым нужны CPU, RAM и диск.
    *   **Coordinating node:** Принимает запросы от клиентов, распределяет их по data-нодам, агрегирует и возвращает результаты. По умолчанию эту роль выполняют все ноды.
    *   **Ingest node:** Выполняет предварительную обработку данных (напр., обогащение, преобразование) перед их индексированием.

**Пример кластера:**
*   **3 Master-eligible ноды** (маленькие, стабильные, не хранят данные).
*   **10 Data-нод** (мощные серверы с большими дисками).
*   **2 Coordinating-only ноды** (только для балансировки входящей нагрузки от клиентов).

#### **3. Apache Lucene**

Каждый **шард** — это не что иное, как отдельный **индекс Apache Lucene**. Lucene — это высокопроизводительная Java-библиотека для полнотекстового поиска. Именно она делает всю "магию" внутри:

*   **Инвертированный индекс:** Главное изобретение. Lucene разбивает весь текст из документов на отдельные слова (токены), нормализует их и создает структуру "слово -> список документов, где оно встречается". Это позволяет находить документы по слову за время O(1), а не перебирать все документы подряд (O(n)).
*   **Сегменты:** Индекс Lucene состоит из неизменяемых сегментов. При записи новых данных создаются новые сегменты. Периодически происходит **слияние (merge)** сегментов для оптимизации и удаления удаленных данных.

---

### **Как его развернуть**

Развертывание Elasticsearch стало очень простым благодаря Docker и готовым пакетам.

#### **1. Локальная разработка (самый быстрый способ)**

**С помощью Docker:**
```bash
# Запуск однодного кластера Elasticsearch
docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:8.11.0

# Проверить работу
curl http://localhost:9200/
```
Elasticsearch будет работать на `http://localhost:9200`.

#### **2. Продакшен-развертывание**

Для production-среды **обязательно** нужно настраивать кластер из нескольких нод.

**Основные шаги:**
1.  **Установка:** Скачать пакет с официального сайта и распаковать на серверах (или использовать Docker/Kubernetes).
2.  **Настройка (`config/elasticsearch.yml`):**
    *   `cluster.name`: Указать одинаковое имя кластера на всех нодах.
    *   `node.name`: Уникальное имя для каждой ноды.
    *   `node.roles`: [ master, data, ingest ] — указать роли ноды.
    *   `network.host`: Указать IP-адрес, который слушает нода (обычно `0.0.0.0`).
    *   `discovery.seed_hosts`: Список master-eligible нод для поиска кластера.
    *   `cluster.initial_master_nodes`: Список нод, участвующих в "бустрэпе" кластера.
3.  **Запуск:** Запустить бинарник Elasticsearch на всех серверах. Ноды автоматически обнаружат друг друга и сформируют кластер.
4.  **Безопасность:** Настроить TLS/SSL для шифрования трафика и встроенный security module для аутентификации и авторизации (в версиях > 7.x включен по умолчанию).

**Современный подход:** Использование оркестраторов like **Kubernetes** с оператором **ECK (Elastic Cloud on Kubernetes)** для автоматического развертывания, масштабирования и управления кластером.

---

### **Что делает Elasticsearch особенным? Его ключевые особенности**

1.  **Невероятно быстрый полнотекстовый поиск.** Благодаря инвертированному индексу Lucene и распределенной архитектуре. Это его главная "фича".

2.  **Мощный и гибкий язык запросов.**
    *   **Query DSL:** Запросы описываются в формате JSON, что позволяет строить очень сложные сценарии поиска (булева логика, фильтрация, ранжирование по релевантности).
    ```json
    {
      "query": {
        "bool": {
          "must":   { "match": { "title": "быстрый поиск" } },
          "filter": { "range": { "date": { "gte": "2023-01-01" } } }
        }
      },
      "aggs": {
        "popular_products": { "terms": { "field": "product_id" } }
      }
    }
    ```

3.  **Аналитика в реальном времени (Агрегации).** Может не только искать, но и вычислять сложные статистические данные по результатам поиска: гистограммы, средние значения, вычисление уникальности (cardinality), геоданные — все это работает на лету по миллиардам документов.

4.  **Горизонтальная масштабируемость и отказоустойчивость.** Добавил больше данных? Просто добавь новые data-ноды в кластер, и шарды автоматически перераспределятся. Шарды-реплики гарантируют, что данные не пропадут при отказе железа.

5.  **Работа с временными рядами и логами.** Идеален для DevOps. Связка **ELK Stack** (Elasticsearch, Logstash, Kibana) — де-факто стандарт для централизованного логирования и мониторинга приложений.

6.  **RESTful API.** Все взаимодействие происходит по простому HTTP API (JSON-in/JSON-out), что позволяет использовать его с любого языка программирования.
    *   `GET /my-index/_search` — поиск
    *   `POST /my-index/_doc` — добавление документа
    *   `PUT /my-index` — создание индекса

---
## Запуск

1. Start:
```bash
docker compose up
```

При первом запуске Elasticsearch автоматически сгенерирует TLS-сертификаты и пароли для встроенных пользователей. Эти логи выводятся в консоль. Чтобы получить сгенерированный пароль для пользователя elastic, выполните:

```bash
docker exec -it elasticsearch /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic -i
```
или протчо из логов:

```bash
docker-compose logs elasticsearch | grep "Password for the elastic"
```

Elasticsearch: Откройте в браузере https://localhost:9200 (или http://localhost:9200 если отключили security). Вас попросит ввести логин (elastic) и пароль (тот, что вы получили/установили на шаге 4).

Kibana: Откройте http://localhost:5601. Для входа используйте те же учетные данные (elastic и пароль).